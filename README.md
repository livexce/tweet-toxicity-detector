ğŸ§  Tweet Toxicity Detector â€“ Projet MLOps
Ce projet vise Ã  dÃ©tecter automatiquement si un tweet est toxique (1) ou non toxique (0) grÃ¢ce Ã  un pipeline MLOps complet.

ğŸš€ Objectifs
Collecter automatiquement des tweets via API.

Nettoyer, transformer et vectoriser les textes.

EntraÃ®ner un modÃ¨le de classification binaire.

Mettre en place des tests, un lint et une CI.

PrÃ©parer le projet pour un futur dÃ©ploiement.

ğŸ§  Cadrage du projet
DonnÃ©es dâ€™entrÃ©e
Type : texte brut (JSON de tweets)

Format : fichier JSON contenant des tweets

DonnÃ©es de sortie
Label binaire :

1 â†’ tweet toxique

0 â†’ tweet non toxique

MÃ©triques dâ€™Ã©valuation
Accuracy

F1-score

ROC-AUC

Contraintes techniques
Latence < 200 ms par requÃªte

Taille du modÃ¨le < 100 Mo

Budget GPU max : T4

ğŸ“š SÃ©ances du projet
ğŸ§  SÃ©ance 1 â€“ Initialisation du projet MLOps
Mise en place de la structure (scripts/, src/, tests/, .github/workflows)

CrÃ©ation de lâ€™environnement virtuel (.venv)

Installation des outils CI : black, flake8, pytest

Configuration de GitHub Actions (CI automatique Ã  chaque push)

ğŸ› ï¸ SÃ©ance 2 â€“ Ingestion des donnÃ©es
CrÃ©ation du scraper avec API ou mock de donnÃ©es

Sauvegarde des tweets bruts dans data/raw/

Tests unitaires du scraper

CI intÃ©grÃ©e avec GitHub Actions

âœ¨ SÃ©ance 3 â€“ PrÃ©traitement NLP
Nettoyage des tweets

Pipeline texte avec spaCy et TfidfVectorizer

Suppression des doublons et NA

Tests unitaires des fonctions NLP

CI opÃ©rationnelle avec flake8, black, pytest

ğŸ“Š SÃ©ance 4 â€“ EDA & Split
Analyse exploratoire (EDA) dans notebooks/4_eda_featurization.ipynb

CrÃ©ation de features : longueur des textes, nb de mots

Split stratifiÃ© : train.csv, val.csv, test.csv

Sauvegarde dans data/processed/

ğŸ¤– SÃ©ance 5 â€“ EntraÃ®nement & Ã‰valuation
Pipeline TF-IDF + LogisticRegression

EntraÃ®nement sur train.csv

Ã‰valuation sur val.csv et test.csv :

Accuracy

F1-score

Matrice de confusion

Sauvegarde du modÃ¨le dans models/toxicity_model.pkl

ğŸ” SÃ©ance 6 â€“ Optimisation des hyperparamÃ¨tres
Test de plusieurs modÃ¨les : RandomForestClassifier, GradientBoostingClassifier

Recherche d'hyperparamÃ¨tres avec GridSearchCV et RandomizedSearchCV

Sauvegarde du meilleur modÃ¨le dans models/best_model.pkl

CI opÃ©rationnelle avec tests et linting (flake8 OK)

ğŸ“ˆ SÃ©ance 7 â€“ Comparaison des modÃ¨les
Ã‰valuation de plusieurs modÃ¨les sur la mÃªme validation set

CrÃ©ation dâ€™un fichier data/metrics/perf_models.csv avec les F1-scores

Visualisation via un barplot dans notebooks/7_compare_models.ipynb

ğŸŒ SÃ©ance 8 â€“ DÃ©ploiement API avec FastAPI
CrÃ©ation de lâ€™API dans scripts/api.py avec FastAPI et Uvicorn

Route /predict pour envoyer un tweet et recevoir une prÃ©diction (0 ou 1)

Dockerisation du projet :

Dockerfile propre

Lancement avec docker run -p 8000:8000 toxicity-api

ModÃ¨le chargÃ© automatiquement au dÃ©marrage
âš™ï¸ Installation
python -m venv .venv
.venv\Scripts\activate      # (Windows)
pip install -r requirements.txt
